# -*- coding: utf-8 -*-
"""BloodCell.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JtC-IKuor3mGig6B9T2IImISVegzNI-i
"""

!pip install kaggle tensorflow opencv-python pandas

from google.colab import files
files.upload()
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download paultimothymooney/blood-cells
!unzip blood-cells.zip -d dataset-master

import os
import pandas as pd
import numpy as np
import cv2
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

DATASET_DIR = os.path.join('dataset-master', 'dataset-master', 'dataset-master')
IMAGE_DIR = os.path.join(DATASET_DIR, 'JPEGImages')
LABELS_FILE = os.path.join(DATASET_DIR, 'labels.csv')
print("Paths set.")

df = pd.read_csv(LABELS_FILE)

df['Category'] = df['Category'].fillna('')
df = df[pd.to_numeric(df['Image'], errors='coerce').notnull()]
df['Image'] = df['Image'].astype(int)

print("First few rows of the cleaned label file:")
print(df.head())

classes = sorted(set(
    cell_type.strip()
    for category in df['Category']
    for cell_type in category.split(',') if cell_type.strip()
))
class_to_index = {cls: idx for idx, cls in enumerate(classes)}
num_classes = len(classes)
print("Classes found:", classes)

def get_images_per_class(class_name, limit=50):
    """Get up to `limit` images for a specific class."""
    filtered_df = df[df['Category'].str.contains(class_name)]
    return filtered_df.sample(min(limit, len(filtered_df)), random_state=42)
selected_df = pd.concat([get_images_per_class(cls) for cls in classes])
selected_df = selected_df.sample(frac=1).reset_index(drop=True)
print(f"Selected {len(selected_df)} images for training.")

def load_and_preprocess_image(img_path):
    """Load and preprocess an image."""
    img = cv2.imread(img_path)
    if img is None:
        return None
    img = cv2.resize(img, (128, 128))
    img = img / 255.0
    return img

X = []
y = []
for _, row in selected_df.iterrows():
    img_file = f"BloodImage_{int(row['Image']):05d}.jpg"
    img_path = os.path.join(IMAGE_DIR, img_file)
    if not os.path.exists(img_path):
        print(f"Warning: Image '{img_file}' not found.")
        continue
    img = load_and_preprocess_image(img_path)
    if img is None:
        print(f"Warning: Failed to load '{img_file}'.")
        continue

    X.append(img)
    label = np.zeros(num_classes)
    for category in row['Category'].split(','):
        cat = category.strip()
        if cat in class_to_index:
            label[class_to_index[cat]] = 1
    y.append(label)

X = np.array(X)
y = np.array(y)
print("Images loaded and preprocessed.")
print(f"Dataset shape: {X.shape}, Labels shape: {y.shape}")

if len(X) == 0 or len(y) == 0:
    raise ValueError("No images were loaded. Please check the image paths and filenames.")

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)
print("Train shape:", X_train.shape)
print("Validation shape:", X_val.shape)

base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))
base_model.trainable = False
x = GlobalAveragePooling2D()(base_model.output)
x = Dense(128, activation='relu')(x)
output = Dense(num_classes, activation='sigmoid')(x)
model = Model(inputs=base_model.input, outputs=output)
model.compile(
    optimizer=Adam(learning_rate=0.0001),
    loss='binary_crossentropy',
    metrics=['accuracy']
)
model.summary()

history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=10,
    batch_size=32
)

def predict_image(image_number, threshold=0.2):
    test_img_file = f"BloodImage_{int(image_number):05d}.jpg"
    test_img_path = os.path.join(IMAGE_DIR, test_img_file)
    if not os.path.exists(test_img_path):
        print(f"Error: Image '{test_img_file}' not found.")
        return
    test_img = load_and_preprocess_image(test_img_path)
    if test_img is None:
        print(f"Error loading image: {test_img_file}")
        return
    test_input = np.expand_dims(test_img, axis=0)
    prediction = model.predict(test_input)[0]
    print("Raw prediction scores:", prediction)
    predicted_labels = [cls for idx, cls in enumerate(classes) if prediction[idx] >= threshold]
    if not predicted_labels:
        top_idx = np.argmax(prediction)
        predicted_labels = [classes[top_idx] + " (low confidence)"]
    plt.imshow(test_img)
    plt.title(f"Predicted: {', '.join(predicted_labels)}")
    plt.axis('off')
    plt.show()

predict_image(5)

predict_image(5)

